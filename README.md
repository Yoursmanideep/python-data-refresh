# Automated Python Data Pipeline with GitHub Actions & MySQL

Welcome to the Automated Python Data Pipeline â€” a slick, hands-off solution that fetches, processes, and stores data in a MySQL database, all powered by GitHub Actions. This setup runs like clockwork every day at 8:00 AM IST (2:30 AM UTC), keeping your data fresh without you lifting a finger. ğŸŒŸ

---

## ğŸ“ Project Structure

Hereâ€™s how the project is laid out â€” clean and simple:

![image](https://github.com/user-attachments/assets/8199ff64-af91-463d-85ae-dc928a4a9ab8)

---

## âš™ï¸ Whatâ€™s the Point?

This pipelineâ€™s got one job â€” and it does it well:

- âœ… Automates Everything: Runs three Python scripts back-to-back
- ğŸ“¦ Updates Your Data: Plugs fresh info into MySQL daily
- â° Set It and Forget It: Scheduled to run at 8:00 AM IST
- ğŸ” Stays Secure: Uses GitHub Actions + Secrets for safe, cloud-based automation

---

## ğŸš€ How It All Comes Together

### ğŸ”„ GitHub Actions: The Brains of the Operation

The workflow lives at .github/workflows/run-python.yml. Hereâ€™s what it does:

#### ğŸ” When it Runs:
- Automatically every day at 2:30 AM UTC (8:00 AM IST)
- Manually on demand via the GitHub Actions tab

#### âš™ï¸ What it Does:
1. Checks out your repository
2. Sets up Python 3.10
3. Installs dependencies from requirements.txt
4. Runs:
   - script1.py
   - script2.py
   - script3.py

---

## ğŸ“¥ What Youâ€™ll Need (Dependencies)

All required libraries live in requirements.txt, including:

- pandas â€” Data wrangling champ
- requests â€” For grabbing data from APIs
- mysql-connector-python â€” MySQLâ€™s best friend
- yfinance â€” For financial data (optional)

These get installed fresh on every workflow run.

---

## ğŸ” Keeping MySQL Safe

No hardcoded credentials here! We use GitHub Secrets to lock things down:

- DB_HOST â€“ Where your database lives
- DB_USER â€“ Whoâ€™s logging in
- DB_PASS â€“ The password
- DB_NAME â€“ Which database to hit

Your scripts use these safely like this:

import os
import mysql.connector

conn = mysql.connector.connect(
    host=os.getenv("DB_HOST"),
    user=os.getenv("DB_USER"),
    password=os.getenv("DB_PASS"),
    database=os.getenv("DB_NAME")
)

Note: Youâ€™ll need a MySQL database hosted somewhere accessible (e.g., AWS RDS, Google Cloud SQL, or a local server with a public IP). GitHub Actions runs in the cloud, so your DB must be reachable!

---

## ğŸ§ª Test It Yourself

Want to kick the tires? Hereâ€™s how to run it manually:

1. Go to your GitHub repo
2. Click the Actions tab
3. Choose "Run Python Scripts Daily"
4. Click Run workflow

Boom â€” instant refresh, perfect for testing or quick reruns.

---

## ğŸ“Š What You Get

This pipeline handles it all:

- Fetch: Pulls data from APIs, files, or other sources
- Process: Cleans and transforms that data
- Store: Inserts or updates data into your MySQL database

Track it all via the workflow logs in the Actions tab.

![image](https://github.com/user-attachments/assets/e82c1934-0d18-416b-a6e6-63ace8487cf0)


---

## ğŸ“Œ Quick Links

Replace yourusername with your GitHub username:

- script1.py: https://github.com/yoursmanideep/python-data-refresh/blob/main/script1.py
- script2.py: https://github.com/yoursmanideep/python-data-refresh/blob/main/script2.py
- script3.py: https://github.comyoursmanideep/python-data-refresh/blob/main/script3.py
- Workflow: https://github.com/yoursmanideep/python-data-refresh/blob/main/.github/workflows/run-python.yml

---

## âœ… Project Status

- âœ… Scripts are locked and loaded
- âœ… MySQL integration secured with GitHub Secrets
- âœ… Daily automation is active
- âœ… Logs available for monitoring/debugging
- âœ… Manual execution enabled

---

## ğŸ¤ Got Ideas?

Maintained by Manideep.  
Feel free to fork, clone, star, or open a pull request if youâ€™d like to contribute.

---

## ğŸ“… Whatâ€™s Next?

- Daily Runs: âœ… Complete
- Error Handling: ğŸ”„ In progress
- Email/Slack Alerts: ğŸ”„ Upcoming
- PostgreSQL Support: â³ Maybe later

---

## ğŸ“‹ How to Get Started

1. Clone this repo or use it directly on GitHub
2. Drop your scripts (script1.py, script2.py, script3.py) in the root
3. Add required libraries to requirements.txt
4. Set these GitHub Secrets:
   - DB_HOST
   - DB_USER
   - DB_PASS
   - DB_NAME
5. Double-check .github/workflows/run-python.yml for accuracy
6. Watch the workflow go in the Actions tab

---

## ğŸ’¡ Pro Tips

- Keep scripts small and modular
- Never hardcode secrets â€” always use environment variables
- Check logs often to catch issues early
- Manually test before relying solely on scheduling
- Troubleshooting: If the workflow fails, verify your MySQL server is online and the Secrets match your DB credentials!

---

## ğŸ“ Letâ€™s Chat

Got questions or want to collaborate?  
ğŸ“§ Email: manideepagoodboy@gmail.com

---
